{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNufxunDS658LSeNHqHX1XB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arogya-gyawali/brainscan_AI/blob/main/notebooks/data_prep/06_build_pytorch_dataloader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîÑ 02_build_pytorch_dataloader.ipynb ‚Äî Custom Dataset and DataLoader\n",
        "\n",
        "This notebook builds and tests a **PyTorch-compatible data loading pipeline** for the BrainScan AI project.\n",
        "\n",
        "---\n",
        "\n",
        "## üß© What It Does\n",
        "\n",
        "- Defines a custom `BrainMRIDataset` class for loading `.png` MRI images using metadata from CSV\n",
        "- Applies torchvision transforms (resizing, normalization)\n",
        "- Returns PyTorch tensors with shape `[batch_size, 1, 224, 224]`\n",
        "- Verifies label loading, shapes, and batch integrity using `DataLoader`\n",
        "\n",
        "---\n",
        "\n",
        "## üì§ Output\n",
        "\n",
        "- `train_loader`, `val_loader`, and `test_loader` objects\n",
        "- Ready-to-use data pipeline for training models\n",
        "\n",
        "> ‚ö†Ô∏è Make sure your image folder path and metadata CSV are correctly linked from your Google Drive.\n"
      ],
      "metadata": {
        "id": "ZsSp-S60GdyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzOipYCyCj8t",
        "outputId": "cfda9fab-29d3-4ffa-85de-299fe8939259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Drive and import libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_root_mri, image_root_healthy, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame containing 'file' and 'label'\n",
        "            image_root_mri (str): Path to tumor MRI image folder\n",
        "            image_root_healthy (str): Path to healthy MRI image folder\n",
        "            transform (torchvision.transforms): Image transformations\n",
        "        \"\"\"\n",
        "        self.df = dataframe\n",
        "        self.image_root_mri = image_root_mri\n",
        "        self.image_root_healthy = image_root_healthy\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        filename = row[\"file\"]\n",
        "\n",
        "        # Choose path based on whether it's a healthy image\n",
        "        if \"IXI\" in filename:\n",
        "            img_path = os.path.join(self.image_root_healthy, filename)\n",
        "        else:\n",
        "            img_path = os.path.join(self.image_root_mri, filename)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = int(row[\"label\"])\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "gDNyLpYTDFtH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# === Paths ===\n",
        "image_root_mri = \"/content/drive/MyDrive/BrainScanAI/BrainScanAI_final_output/mri\"\n",
        "image_root_healthy = \"/content/drive/MyDrive/BrainScanAI/BrainScanAI_final_output/no_tumor_IXI_png\"\n",
        "\n",
        "# Load split metadata\n",
        "split_path = \"/content/drive/MyDrive/BrainScanAI/splits\"\n",
        "train_df = pd.read_csv(os.path.join(split_path, \"train.csv\"))\n",
        "val_df   = pd.read_csv(os.path.join(split_path, \"val.csv\"))\n",
        "test_df  = pd.read_csv(os.path.join(split_path, \"test.csv\"))\n",
        "\n",
        "# Define transforms (resize to 224x224 + normalize)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# === Create Dataset Instances ===\n",
        "train_dataset = BrainMRIDataset(train_df, image_root_mri, image_root_healthy, transform)\n",
        "val_dataset   = BrainMRIDataset(val_df, image_root_mri, image_root_healthy, transform)\n",
        "test_dataset  = BrainMRIDataset(test_df, image_root_mri, image_root_healthy, transform)\n",
        "\n",
        "# === Create DataLoaders ===\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "8HlQvOtuDSuw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(\"Batch shape:\", images.shape)   # (batch_size, 1, 224, 224)\n",
        "print(\"Labels:\", labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkOpMfkdDU4e",
        "outputId": "5df39674-7ad9-4117-e5c2-a85e1b367e41"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([32, 1, 224, 224])\n",
            "Labels: tensor([0, 0, 0, 0, 2, 2, 0, 2, 3, 1, 2, 2, 0, 1, 3, 1, 1, 3, 0, 2, 3, 3, 2, 3,\n",
            "        2, 0, 2, 0, 2, 2, 3, 3])\n"
          ]
        }
      ]
    }
  ]
}